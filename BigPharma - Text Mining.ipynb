{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import re\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "\n",
    "companies_mapping = {'AZN_stocks.csv':\"AstraZeneca\", 'RHHBY_stocks.csv':\"Roche\", 'PFE_stocks.csv':\"Pfizer\", \n",
    "                     'NVS_stocks.csv':\"Novartis\",'BAYRY_stocks.csv':\"BayerPharma\", 'MRK_stocks.csv':\"Merck\", \n",
    "                     'GSK_stocks.csv':\"GSK\", 'SNY_stocks.csv':\"Sanofi\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter = glob('input/tweets/*.csv')\n",
    "df_tweets = pd.concat(pd.read_csv(file).assign(filename = file) for file in twitter)\n",
    "\n",
    "stock = glob('input/stock/*.csv')\n",
    "df_stock = pd.concat(pd.read_csv(file).assign(filename = file) for file in stock)\n",
    "\n",
    "df_stock.filename = df_stock.filename.str.split(pat =\"\\\\\", expand = True)[1]\n",
    "df_stock['company'] = df_stock.filename.map(companies_mapping)\n",
    "\n",
    "df_covid = pd.read_csv('input/covid_data.csv')\n",
    "df_tweets.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "del df_tweets['filename']\n",
    "del df_tweets['index']\n",
    "\n",
    "del df_stock['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_hashes(col):\n",
    "\n",
    "    return list(set([re.sub('[^\\w\\s]','', word) for word in col.split() if word[0] == '#']))\n",
    "\n",
    "def return_ats(col):\n",
    "    return list(set(  [re.sub('[^\\w\\s]','', word) for word in col.split() if word[0] == '@']  ))\n",
    "\n",
    "def remove_stopwords(col):\n",
    "    return ' '.join([word for word in col.split() if word not in stop])\n",
    "\n",
    "def remove_https(col):\n",
    "    return ' '.join([word for word in col.split() if word[0:6] != 'https:'])\n",
    "\n",
    "def text_tokenized(col):\n",
    "    return word_tokenize(col)\n",
    "\n",
    "def pos_tagged(col):\n",
    "    return pos_tag(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower column names\n",
    "df_tweets.columns = map(str.lower, df_tweets.columns)\n",
    "df_stock.columns = map(str.lower, df_stock.columns)\n",
    "\n",
    "df_tweets.rename(columns = {'text':'text_original'}, inplace = True)\n",
    "\n",
    "df_tweets['text_modified'] = df_tweets['text_original'].str.lower() # małe znaki\n",
    "df_tweets['hash'] = df_tweets['text_modified'].apply(return_hashes) # wybieranie unikalnych hashtagów (bez punktuacji)\n",
    "df_tweets['at'] = df_tweets['text_modified'].apply(return_ats) # wybieranie unikalnych odnośników (bez punktuacji)\n",
    "df_tweets['text_modified'] = df_tweets['text_modified'].apply(remove_https)\n",
    "df_tweets['text_modified'] = df_tweets['text_modified'].str.replace('[^\\w\\s]','') # usuwanie punktuacji; można usuwać # ze zdań jeśli usunie się ten znak z regular expression\n",
    "df_tweets['text_modified'] = df_tweets['text_modified'].apply(remove_stopwords)\n",
    "df_tweets['text_tokenized'] = df_tweets['text_modified'].apply(text_tokenized)\n",
    "df_tweets['text_pos_tagged'] = df_tweets['text_tokenized'].apply(pos_tagged)\n",
    "\n",
    "df_tweets.created_at = pd.to_datetime(df_tweets.created_at)\n",
    "df_tweets['date'] = df_tweets.created_at.dt.date\n",
    "\n",
    "df_stock.date = pd.to_datetime(df_stock.date)\n",
    "df_stock['date'] = df_stock.date.dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakres datowy dla tweetów   2020-02-03 11:30:17   -   2020-05-06 13:13:41   :  AstraZeneca\n",
      "Zakres datowy dla tweetów   2020-02-03 16:39:56   -   2020-05-06 16:40:37   :  BayerPharma\n",
      "Zakres datowy dla tweetów   2020-02-05 12:26:23   -   2020-05-07 15:41:11   :  GSK\n",
      "Zakres datowy dla tweetów   2020-02-04 14:59:51   -   2020-05-07 18:10:43   :  Merck\n",
      "Zakres datowy dla tweetów   2020-02-03 13:22:07   -   2020-05-07 19:55:40   :  Novartis\n",
      "Zakres datowy dla tweetów   2020-02-17 13:55:00   -   2020-05-07 20:02:01   :  Pfizer\n",
      "Zakres datowy dla tweetów   2020-02-03 09:01:21   -   2020-05-07 14:24:05   :  Roche\n",
      "Zakres datowy dla tweetów   2020-02-03 10:03:21   -   2020-05-05 12:59:16   :  Sanofi\n"
     ]
    }
   ],
   "source": [
    "companies = df_tweets.company.unique()\n",
    "\n",
    "for company in companies:\n",
    "    dat1 = min(df_tweets.loc[df_tweets['company'] == company].created_at)\n",
    "    dat2 = max(df_tweets.loc[df_tweets['company'] == company].created_at)\n",
    "    \n",
    "    print(f'Zakres datowy dla tweetów   {dat1}   -   {dat2}   :  {company}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze względy na ograniczenie API Twittera dla każdej firmy pobranych zostało 200 tweetów. Zakres czasowy ich występowania różni się dla danych firm. Dlatego ustalony zostaje wspólny okres badania: od 1 lutego do 7 maja. Początego tego okresu można uznać za początek epidemii koronawirusa w Europie i Ameryce Północnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_date = datetime.strptime('2020-02-02','%Y-%m-%d').date()\n",
    "\n",
    "df_tweets = df_tweets.loc[df_tweets['date'] >= lower_date]\n",
    "df_stock = df_stock.loc[df_stock['date'] >= lower_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponowne sprawdzenie zakresu dat, tym razem z ilością tweetów pozostałą po ograniczeniu zbioru danych dla każdej z firm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakres datowy dla tweetów   2020-02-03 11:30:17   -   2020-05-06 13:13:41   :  AstraZeneca; il. tweetów: 107\n",
      "Zakres datowy dla tweetów   2020-02-03 16:39:56   -   2020-05-06 16:40:37   :  BayerPharma; il. tweetów: 65\n",
      "Zakres datowy dla tweetów   2020-02-05 12:26:23   -   2020-05-07 15:41:11   :  GSK; il. tweetów: 200\n",
      "Zakres datowy dla tweetów   2020-02-04 14:59:51   -   2020-05-07 18:10:43   :  Merck; il. tweetów: 200\n",
      "Zakres datowy dla tweetów   2020-02-03 13:22:07   -   2020-05-07 19:55:40   :  Novartis; il. tweetów: 106\n",
      "Zakres datowy dla tweetów   2020-02-17 13:55:00   -   2020-05-07 20:02:01   :  Pfizer; il. tweetów: 200\n",
      "Zakres datowy dla tweetów   2020-02-03 09:01:21   -   2020-05-07 14:24:05   :  Roche; il. tweetów: 195\n",
      "Zakres datowy dla tweetów   2020-02-03 10:03:21   -   2020-05-05 12:59:16   :  Sanofi; il. tweetów: 193\n"
     ]
    }
   ],
   "source": [
    "companies = df_tweets.company.unique()\n",
    "\n",
    "for company in companies:\n",
    "    dat1 = min(df_tweets.loc[df_tweets['company'] == company].created_at)\n",
    "    dat2 = max(df_tweets.loc[df_tweets['company'] == company].created_at)\n",
    "    ilosc = len(df_tweets.loc[df_tweets['company'] == company])\n",
    "    print(f'Zakres datowy dla tweetów   {dat1}   -   {dat2}   :  {company}; il. tweetów: {ilosc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać dla BayerPharmy ta ilość jest mniejsza niż poprzednio połowa. Ewentualnością będzie wykluczenie tej firmy z badania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>text_original</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text_modified</th>\n",
       "      <th>hash</th>\n",
       "      <th>at</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_pos_tagged</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>Together with partners across industry, academia and government, we are taking a multipronged approach to helping patients around the world facing #COVID19. https://t.co/uQuHj6BkBN</td>\n",
       "      <td>2020-05-06 13:13:41</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>together partners across industry academia government taking multipronged approach helping patients around world facing covid19</td>\n",
       "      <td>[covid19]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[together, partners, across, industry, academia, government, taking, multipronged, approach, helping, patients, around, world, facing, covid19]</td>\n",
       "      <td>[(together, RB), (partners, NNS), (across, IN), (industry, NN), (academia, NN), (government, NN), (taking, VBG), (multipronged, VBD), (approach, NN), (helping, VBG), (patients, NNS), (around, IN), (world, NN), (facing, NN), (covid19, NN)]</td>\n",
       "      <td>2020-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>On #GivingTuesdayNow we stand with our partners @Plan_UK @Unicef_UK @ProjectHopeorg @NCDAlliance in their efforts responding to the unique health needs of groups vulnerable to #COVID19, such as those living with NCDs and young people. Get involved: https://t.co/YGRHLGqct6 https://t.co/vePEeAne49</td>\n",
       "      <td>2020-05-05 16:27:03</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>givingtuesdaynow stand partners plan_uk unicef_uk projecthopeorg ncdalliance efforts responding unique health needs groups vulnerable covid19 living ncds young people get involved</td>\n",
       "      <td>[covid19, givingtuesdaynow]</td>\n",
       "      <td>[projecthopeorg, unicef_uk, plan_uk, ncdalliance]</td>\n",
       "      <td>[givingtuesdaynow, stand, partners, plan_uk, unicef_uk, projecthopeorg, ncdalliance, efforts, responding, unique, health, needs, groups, vulnerable, covid19, living, ncds, young, people, get, involved]</td>\n",
       "      <td>[(givingtuesdaynow, JJ), (stand, VBP), (partners, NNS), (plan_uk, VBP), (unicef_uk, JJ), (projecthopeorg, JJ), (ncdalliance, NN), (efforts, NNS), (responding, VBG), (unique, JJ), (health, NN), (needs, NNS), (groups, NNS), (vulnerable, JJ), (covid19, JJ), (living, NN), (ncds, JJ), (young, JJ), (people, NNS), (get, VBP), (involved, VBN)]</td>\n",
       "      <td>2020-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>We’re #standingtogether4asthma with patients and the respiratory community during these times of uncertainty. Visit @WEF to learn more about what we’re doing to play our part in the fight against #COVID19: #WorldAsthmaDay   \\r\\nhttps://t.co/fWE7ik8rNs https://t.co/Z54pyHBENq</td>\n",
       "      <td>2020-05-05 12:30:15</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>standingtogether4asthma patients respiratory community times uncertainty visit wef learn play part fight covid19 worldasthmaday</td>\n",
       "      <td>[covid19, standingtogether4asthma, worldasthmaday]</td>\n",
       "      <td>[wef]</td>\n",
       "      <td>[standingtogether4asthma, patients, respiratory, community, times, uncertainty, visit, wef, learn, play, part, fight, covid19, worldasthmaday]</td>\n",
       "      <td>[(standingtogether4asthma, NN), (patients, NNS), (respiratory, VBP), (community, NN), (times, NNS), (uncertainty, NN), (visit, NN), (wef, NN), (learn, VBP), (play, VB), (part, NN), (fight, NN), (covid19, NN), (worldasthmaday, NN)]</td>\n",
       "      <td>2020-05-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company  \\\n",
       "0  AstraZeneca   \n",
       "1  AstraZeneca   \n",
       "2  AstraZeneca   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              text_original  \\\n",
       "0  Together with partners across industry, academia and government, we are taking a multipronged approach to helping patients around the world facing #COVID19. https://t.co/uQuHj6BkBN                                                                                                                       \n",
       "1  On #GivingTuesdayNow we stand with our partners @Plan_UK @Unicef_UK @ProjectHopeorg @NCDAlliance in their efforts responding to the unique health needs of groups vulnerable to #COVID19, such as those living with NCDs and young people. Get involved: https://t.co/YGRHLGqct6 https://t.co/vePEeAne49   \n",
       "2  We’re #standingtogether4asthma with patients and the respiratory community during these times of uncertainty. Visit @WEF to learn more about what we’re doing to play our part in the fight against #COVID19: #WorldAsthmaDay   \\r\\nhttps://t.co/fWE7ik8rNs https://t.co/Z54pyHBENq                        \n",
       "\n",
       "           created_at  favourite_count  retweet_count  \\\n",
       "0 2020-05-06 13:13:41  44               8               \n",
       "1 2020-05-05 16:27:03  32               8               \n",
       "2 2020-05-05 12:30:15  19               7               \n",
       "\n",
       "                                                                                                                                                                         text_modified  \\\n",
       "0  together partners across industry academia government taking multipronged approach helping patients around world facing covid19                                                       \n",
       "1  givingtuesdaynow stand partners plan_uk unicef_uk projecthopeorg ncdalliance efforts responding unique health needs groups vulnerable covid19 living ncds young people get involved   \n",
       "2  standingtogether4asthma patients respiratory community times uncertainty visit wef learn play part fight covid19 worldasthmaday                                                       \n",
       "\n",
       "                                                 hash  \\\n",
       "0  [covid19]                                            \n",
       "1  [covid19, givingtuesdaynow]                          \n",
       "2  [covid19, standingtogether4asthma, worldasthmaday]   \n",
       "\n",
       "                                                  at  \\\n",
       "0  []                                                  \n",
       "1  [projecthopeorg, unicef_uk, plan_uk, ncdalliance]   \n",
       "2  [wef]                                               \n",
       "\n",
       "                                                                                                                                                                                              text_tokenized  \\\n",
       "0  [together, partners, across, industry, academia, government, taking, multipronged, approach, helping, patients, around, world, facing, covid19]                                                             \n",
       "1  [givingtuesdaynow, stand, partners, plan_uk, unicef_uk, projecthopeorg, ncdalliance, efforts, responding, unique, health, needs, groups, vulnerable, covid19, living, ncds, young, people, get, involved]   \n",
       "2  [standingtogether4asthma, patients, respiratory, community, times, uncertainty, visit, wef, learn, play, part, fight, covid19, worldasthmaday]                                                              \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                     text_pos_tagged  \\\n",
       "0  [(together, RB), (partners, NNS), (across, IN), (industry, NN), (academia, NN), (government, NN), (taking, VBG), (multipronged, VBD), (approach, NN), (helping, VBG), (patients, NNS), (around, IN), (world, NN), (facing, NN), (covid19, NN)]                                                                                                      \n",
       "1  [(givingtuesdaynow, JJ), (stand, VBP), (partners, NNS), (plan_uk, VBP), (unicef_uk, JJ), (projecthopeorg, JJ), (ncdalliance, NN), (efforts, NNS), (responding, VBG), (unique, JJ), (health, NN), (needs, NNS), (groups, NNS), (vulnerable, JJ), (covid19, JJ), (living, NN), (ncds, JJ), (young, JJ), (people, NNS), (get, VBP), (involved, VBN)]   \n",
       "2  [(standingtogether4asthma, NN), (patients, NNS), (respiratory, VBP), (community, NN), (times, NNS), (uncertainty, NN), (visit, NN), (wef, NN), (learn, VBP), (play, VB), (part, NN), (fight, NN), (covid19, NN), (worldasthmaday, NN)]                                                                                                              \n",
       "\n",
       "         date  \n",
       "0  2020-05-06  \n",
       "1  2020-05-05  \n",
       "2  2020-05-05  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>48.619999</td>\n",
       "      <td>48.930000</td>\n",
       "      <td>48.450001</td>\n",
       "      <td>48.509998</td>\n",
       "      <td>47.541225</td>\n",
       "      <td>1990900</td>\n",
       "      <td>AstraZeneca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>48.759998</td>\n",
       "      <td>49.090000</td>\n",
       "      <td>48.720001</td>\n",
       "      <td>48.759998</td>\n",
       "      <td>47.786232</td>\n",
       "      <td>1698800</td>\n",
       "      <td>AstraZeneca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>49.459999</td>\n",
       "      <td>49.849998</td>\n",
       "      <td>49.230000</td>\n",
       "      <td>49.730000</td>\n",
       "      <td>48.736862</td>\n",
       "      <td>2303000</td>\n",
       "      <td>AstraZeneca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date       open       high        low      close  adj close  \\\n",
       "63  2020-02-03  48.619999  48.930000  48.450001  48.509998  47.541225   \n",
       "64  2020-02-04  48.759998  49.090000  48.720001  48.759998  47.786232   \n",
       "65  2020-02-05  49.459999  49.849998  49.230000  49.730000  48.736862   \n",
       "\n",
       "     volume      company  \n",
       "63  1990900  AstraZeneca  \n",
       "64  1698800  AstraZeneca  \n",
       "65  2303000  AstraZeneca  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Darciu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Darciu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
